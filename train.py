"""
√âtape 4 : Entra√Ænement et validation du mod√®le CNN
- S√©paration des donn√©es (train/validation)
- Optimisation avec Adam et entropie crois√©e
- Pr√©vention du surapprentissage (dropout, augmentation, callbacks)
"""

import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime

from preprocessing import create_data_generators
from model import build_cnn_model, compile_model, create_callbacks


def train_model(
    data_dir="data",
    epochs=50,
    batch_size=32,
    validation_split=0.2,
    learning_rate=0.001,
    save_best_model=True,
    model_save_path="models/best_model.h5"
):
    """
    Entra√Æne le mod√®le CNN pour la reconnaissance d'animaux
    
    Args:
        data_dir: R√©pertoire contenant les images par classe
        epochs: Nombre d'√©poques d'entra√Ænement
        batch_size: Taille des lots
        validation_split: Proportion des donn√©es pour la validation (20-30%)
        learning_rate: Taux d'apprentissage
        save_best_model: Sauvegarder le meilleur mod√®le
        model_save_path: Chemin pour sauvegarder le mod√®le
        
    Returns:
        model: Mod√®le entra√Æn√©
        history: Historique d'entra√Ænement
    """
    
    print("=" * 60)
    print("ENTRA√éNEMENT DU MOD√àLE CNN")
    print("=" * 60)
    
    # ========== 1. S√âPARATION DES DONN√âES ==========
    print("\nüìä √âtape 1 : S√©paration des donn√©es")
    print(f"   - Ensemble d'entra√Ænement : {int((1-validation_split)*100)}%")
    print(f"   - Ensemble de validation : {int(validation_split*100)}%")
    
    train_gen, val_gen, class_names = create_data_generators(
        data_dir=data_dir,
        target_size=(224, 224),
        batch_size=batch_size,
        validation_split=validation_split
    )
    
    num_classes = len(class_names)
    print(f"   ‚úì {num_classes} classes d√©tect√©es: {class_names}")
    print(f"   ‚úì {train_gen.samples} images d'entra√Ænement")
    print(f"   ‚úì {val_gen.samples} images de validation")
    
    # ========== 2. CONSTRUCTION DU MOD√àLE ==========
    print("\nüî® √âtape 2 : Construction du mod√®le")
    model = build_cnn_model(
        input_shape=(224, 224, 3),
        num_classes=num_classes
    )
    
    # ========== 3. OPTIMISATION ==========
    print("\n‚öôÔ∏è  √âtape 3 : Configuration de l'optimisation")
    print(f"   - Optimiseur : Adam")
    print(f"   - Taux d'apprentissage : {learning_rate}")
    print(f"   - Fonction de perte : categorical_crossentropy")
    print(f"   - M√©triques : accuracy, top_k_categorical_accuracy")
    
    model = compile_model(model, learning_rate=learning_rate)
    
    # Afficher le r√©sum√©
    print("\nüìã R√©sum√© du mod√®le :")
    total_params = model.count_params()
    print(f"   - Param√®tres totaux : {total_params:,}")
    
    # ========== 4. PR√âVENTION DU SURAPPRENTISSAGE ==========
    print("\nüõ°Ô∏è  √âtape 4 : Pr√©vention du surapprentissage")
    print("   ‚úì Augmentation des donn√©es (rotation, zoom, retournement)")
    print("   ‚úì Dropout dans les couches denses (0.5 et 0.3)")
    print("   ‚úì BatchNormalization pour stabiliser l'entra√Ænement")
    print("   ‚úì EarlyStopping : arr√™t si pas d'am√©lioration")
    print("   ‚úì ReduceLROnPlateau : r√©duction du learning rate si plateau")
    
    # Cr√©er les callbacks
    callbacks = create_callbacks()
    
    # Ajouter des callbacks suppl√©mentaires
    if save_best_model:
        # Cr√©er le dossier models s'il n'existe pas
        os.makedirs(os.path.dirname(model_save_path), exist_ok=True)
        
        callbacks.append(
            ModelCheckpoint(
                filepath=model_save_path,
                monitor='val_accuracy',
                save_best_only=True,
                mode='max',
                verbose=1,
                save_weights_only=False
            )
        )
        print(f"   ‚úì ModelCheckpoint : sauvegarde du meilleur mod√®le dans '{model_save_path}'")
    
    # Logger CSV pour l'historique
    csv_logger = CSVLogger('training_history.csv', append=False)
    callbacks.append(csv_logger)
    print(f"   ‚úì CSVLogger : historique sauvegard√© dans 'training_history.csv'")
    
    # ========== 5. ENTRA√éNEMENT ==========
    print("\nüöÄ √âtape 5 : D√©marrage de l'entra√Ænement")
    print(f"   - Nombre d'√©poques : {epochs}")
    print(f"   - Taille des lots : {batch_size}")
    print(f"   - Steps par √©poque (train) : {len(train_gen)}")
    print(f"   - Steps par √©poque (validation) : {len(val_gen)}")
    print("\n" + "-" * 60)
    
    # Calculer les steps par √©poque
    steps_per_epoch = len(train_gen)
    validation_steps = len(val_gen)
    
    # Entra√Æner le mod√®le
    history = model.fit(
        train_gen,
        steps_per_epoch=steps_per_epoch,
        epochs=epochs,
        validation_data=val_gen,
        validation_steps=validation_steps,
        callbacks=callbacks,
        verbose=1
    )
    
    print("-" * 60)
    print("\n‚úÖ Entra√Ænement termin√© !")
    
    # Afficher les meilleures performances
    best_val_acc = max(history.history['val_accuracy'])
    best_val_loss = min(history.history['val_loss'])
    best_epoch = np.argmax(history.history['val_accuracy']) + 1
    
    print(f"\nüìä Meilleures performances :")
    print(f"   - Meilleure pr√©cision de validation : {best_val_acc:.4f} ({best_val_acc*100:.2f}%)")
    print(f"   - Meilleure perte de validation : {best_val_loss:.4f}")
    print(f"   - √âpoque : {best_epoch}")
    
    # V√©rifier si l'objectif de 66% est atteint
    if best_val_acc >= 0.66:
        print(f"\nüéâ Objectif atteint ! Pr√©cision >= 66% ({best_val_acc*100:.2f}%)")
    else:
        print(f"\n‚ö†Ô∏è  Objectif non atteint. Pr√©cision actuelle : {best_val_acc*100:.2f}% (objectif : 66%)")
    
    return model, history


def plot_training_history(history, save_path='training_curves.png'):
    """
    Visualise l'historique d'entra√Ænement
    
    Args:
        history: Historique retourn√© par model.fit()
        save_path: Chemin pour sauvegarder le graphique
    """
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))
    
    # Graphique 1 : Pr√©cision
    axes[0].plot(history.history['accuracy'], label='Pr√©cision (entra√Ænement)', marker='o')
    axes[0].plot(history.history['val_accuracy'], label='Pr√©cision (validation)', marker='s')
    axes[0].set_xlabel('√âpoque')
    axes[0].set_ylabel('Pr√©cision')
    axes[0].set_title('√âvolution de la pr√©cision')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)
    axes[0].axhline(y=0.66, color='r', linestyle='--', label='Objectif (66%)')
    axes[0].legend()
    
    # Graphique 2 : Perte
    axes[1].plot(history.history['loss'], label='Perte (entra√Ænement)', marker='o')
    axes[1].plot(history.history['val_loss'], label='Perte (validation)', marker='s')
    axes[1].set_xlabel('√âpoque')
    axes[1].set_ylabel('Perte')
    axes[1].set_title('√âvolution de la perte')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\n‚úì Graphiques sauvegard√©s dans '{save_path}'")
    plt.show()


if __name__ == "__main__":
    # Configuration
    DATA_DIR = "data"
    EPOCHS = 50
    BATCH_SIZE = 32
    VALIDATION_SPLIT = 0.2  # 20% pour validation (80% entra√Ænement)
    LEARNING_RATE = 0.001
    
    # Entra√Æner le mod√®le
    model, history = train_model(
        data_dir=DATA_DIR,
        epochs=EPOCHS,
        batch_size=BATCH_SIZE,
        validation_split=VALIDATION_SPLIT,
        learning_rate=LEARNING_RATE,
        save_best_model=True,
        model_save_path="models/best_model.h5"
    )
    
    # Visualiser l'historique
    print("\nüìà G√©n√©ration des graphiques d'entra√Ænement...")
    plot_training_history(history)
    
    print("\n" + "=" * 60)
    print("‚úì Entra√Ænement termin√© avec succ√®s !")
    print("=" * 60)
    print("\nFichiers g√©n√©r√©s :")
    print("  - models/best_model.h5 : Meilleur mod√®le sauvegard√©")
    print("  - training_history.csv : Historique d√©taill√©")
    print("  - training_curves.png : Graphiques de performance")
